{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "098621eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tensorboardX import SummaryWriter\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee9bd5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "dtype = torch.float32\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "max_epochs = 1500\n",
    "\n",
    "local_img_dim = 10 # pixels of local map length\n",
    "y_dim = local_img_dim * local_img_dim +1\n",
    "x_dim = 3\n",
    "dim_latent = 3\n",
    "dim_hidden = 512\n",
    "\n",
    "train_valid_ratio = 0.95 # % for train\n",
    "batchSize = 256\n",
    "\n",
    "dropout = 0.2\n",
    "learning_rate = 0.0001\n",
    "kl_weight = 1\n",
    "\n",
    "# loss function\n",
    "criteria = torch.nn.MSELoss() # 1/n*Sum((xi-yi)**2)\n",
    "\n",
    "#####################################\n",
    "#------------Suggestions------------#\n",
    "# 1. tune KL weight --> size of latent space --> add new hidden layers\n",
    "# 2. tune KL weight from small value to big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d638e22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.len = len(data)\n",
    "        self.list_IDs = np.arange(0,len(data))\n",
    "        self.data = data  # npy data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        ID = self.list_IDs[item]\n",
    "        x = self.data[ID]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a391e63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "data = np.load('sample_0418.npy') # numpy.ndarray\n",
    "# print(\"number of terrain samples:\", len(data))\n",
    "data_training = data[0:int(train_valid_ratio * len(data))]\n",
    "data_validation = data[int(train_valid_ratio * len(data)):]\n",
    "data_training_set = Dataset(data_training)\n",
    "data_training_generator = torch.utils.data.DataLoader(data_training_set, batch_size=batchSize, shuffle=True, num_workers=2)\n",
    "data_validation_set = Dataset(data_validation)\n",
    "data_validation_generator = torch.utils.data.DataLoader(data_validation_set, batch_size=batchSize, shuffle=True, num_workers=2)\n",
    "\n",
    "# print(len(data_training_set))\n",
    "# print(type(data_training_set[50]))\n",
    "# print(data_training_set[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdbc244a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define CVAE model\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super().__init__() # init nn.Module\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, H)\n",
    "        self.linear_mu = torch.nn.Linear(H, D_out)\n",
    "        self.linear_logvar = torch.nn.Linear(H, D_out)\n",
    "        self.dropout = torch.nn.Dropout(p=dropout) # p – probability of an element to be zeroed\n",
    "        self.H = H\n",
    "    # Encoder Q netowrk, approximate the latent feature with gaussian distribution,output mu and logvar\n",
    "    # Q(z|x) = N(z|mu(X),sigma(X))\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.linear2(x))\n",
    "        return self.linear_mu(x), self.linear_logvar(x)\n",
    "    \n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super().__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, H)\n",
    "        self.linear3 = torch.nn.Linear(H, D_out)\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "    # Decoder P network, sampling from normal distribution and build the reconstruction\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.linear2(x))\n",
    "        return self.linear3(x)\n",
    "\n",
    "class CVAE(torch.nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    def _reparameterize(self, mu, logvar):\n",
    "        eps = torch.randn_like(mu)\n",
    "        return mu + torch.exp(logvar / 2) * eps\n",
    "    def forward(self, state, cond):\n",
    "        x_in = torch.cat((state, cond),1)\n",
    "        mu, logvar = self.encoder(x_in)\n",
    "        z = self._reparameterize(mu, logvar)\n",
    "        z_in = torch.cat((z, cond), 1)\n",
    "        return mu, logvar, self.decoder(z_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd2312f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply CVAE\n",
    "encoder = Encoder(x_dim + y_dim, dim_hidden, dim_latent)\n",
    "decoder = Decoder(dim_latent + y_dim, dim_hidden, x_dim)\n",
    "model = CVAE(encoder, decoder)\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2eacf1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start logging\n",
    "description = \"_description\"\n",
    "folder = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\") + description\n",
    "writer = SummaryWriter(\"runs/\" + folder)\n",
    "os.makedirs(name=\"policies\", exist_ok=True)\n",
    "os.makedirs(name=\"policies/\" + folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2218333f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= start training ============\n",
      "tensor(1.5679, device='cuda:0', grad_fn=<MeanBackward1>)\n",
      "1.5678539276123047\n",
      "========= training end ============\n"
     ]
    }
   ],
   "source": [
    "# main training process\n",
    "try:\n",
    "    print(\"========= start training ============\")\n",
    "    for epoch in range(max_epochs):\n",
    "        epoch_loss = []\n",
    "        for local_batch in data_training_generator:\n",
    "            x_train = local_batch[:,  0  :x_dim].type(dtype).to(device)\n",
    "            y_train = local_batch[:,x_dim:     ].type(dtype).to(device)\n",
    "            optimizer.zero_grad()\n",
    "            mu, logvar, recon_batch = model(x_train,y_train) #mu 256*3 ... \n",
    "            recon_loss = criteria(recon_batch, x_train)      # recon_loss 1*1\n",
    "            kl_loss = 1000*kl_weight * torch.sum(torch.exp(logvar) + mu ** 2 - 1 - logvar, 1) # kl_loss 1*256, 一整个batch的kl loss\n",
    "            \n",
    "            loss = torch.mean(recon_loss + kl_loss, 0)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss.append(loss.item())\n",
    "            \n",
    "            KLLOSS = torch.mean(kl_loss,0)\n",
    "            print(KLLOSS)\n",
    "            KLLOSS_2 = loss.item() - recon_loss.item()\n",
    "            print(KLLOSS_2)\n",
    "        writer.add_scalar('training/loss', np.mean(np.array(epoch_loss)), epoch)\n",
    "        #print(\"epoch: {}, Loss: {}\".format(epoch,np.mean((np.array(epoch_loss))),))\n",
    "     \n",
    "    # validation\n",
    "        if epoch % 1 == 0 and epoch > 0:\n",
    "            with torch.no_grad():\n",
    "                recon_loss_viz, kl_loss_viz, loss_viz = [], [], []\n",
    "                for local_batch in data_validation_generator:\n",
    "                    x_validate = local_batch[:, 0:x_dim].type(dtype).to(device)\n",
    "                    y_validate = local_batch[:, x_dim:].type(dtype).to(device)\n",
    "                    mu, logvar, recon_batch = model(x_validate, y_validate)\n",
    "                    recon_loss = criteria(recon_batch, x_validate)\n",
    "                    kl_loss =  kl_weight * torch.sum(torch.exp(logvar) + mu ** 2 - 1 - logvar, 1)\n",
    "                    loss = torch.mean(recon_loss + kl_loss, 0)\n",
    "                    recon_loss_viz.append(recon_loss.item())\n",
    "                    loss_viz.append(loss.item())\n",
    "                    kl_loss_viz.append(loss.item() - recon_loss.item())\n",
    "                writer.add_scalar('validation/recon_loss', np.mean(np.array(recon_loss_viz)), epoch)\n",
    "                writer.add_scalar('validation/kl_loss', np.mean((np.array(kl_loss_viz))), epoch)\n",
    "                writer.add_scalar('validation/loss', np.mean((np.array(loss_viz))), epoch)\n",
    "                #print(\"epoch: {}, Loss: {}, Recon_loss: {}, KL_loss: {}\".format(epoch,np.mean((np.array(loss_viz))),\n",
    "                                                                               # np.mean(np.array(recon_loss_viz)),\n",
    "                                                                               # np.mean((np.array(kl_loss_viz)))))\n",
    "    # save intermediate model\n",
    "        #if epoch % 1000 == 0 and epoch > 0:\n",
    "            # print(\"Saving intermediate model.\")\n",
    "            # save_path = \"policies/\" + \"final.pt\"\n",
    "            # torch.save(model, f=save_path)\n",
    "\n",
    "    # save final model\n",
    "    # print(\"Finishing training, Saving final model.\")\n",
    "    # save_path = \"policies/final.pt\"\n",
    "    # torch.save(model, f=save_path)\n",
    "    print(\"========= training end ============\")\n",
    "    \n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Training interupted.\")\n",
    "    # save_path = \"policies/final.pt\"\n",
    "    # torch.save(model, f=save_path)\n",
    "writer.close()\n",
    "\n",
    "# tensorboard --logdir=./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6127da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73fed7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19200"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d37bf112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.587600000000005e-09"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-3.7253e-08+3.9116e-08+-7.4506e-09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e22de59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
