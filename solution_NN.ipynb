{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "34b59988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a Neural Network by Pytorch\n",
    "# for imbalanced binary classification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "29458101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "train_csv = pd.read_csv(\"train.csv\")  # 112000*'ABCD' - 0/1\n",
    "predict_csv = pd.read_csv(\"test.csv\") # 48000*'ABCD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "de93b222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data encoding\n",
    "dict = {'A':0, 'C':1, 'D':2, 'E':3, 'F':4,\n",
    "        'G':5, 'H':6, 'I':7, 'K':8, 'L':9,\n",
    "        'M':10, 'N':11, 'P':12, 'Q':13, 'R':14,\n",
    "        'S':15, 'T':16, 'U':17, 'V':18, 'W':19, 'Y':20}\n",
    "def encoding(data):\n",
    "    results = np.zeros((data.shape[0],21*4))\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(4):\n",
    "            results[i][21*j+dict[data[i][j]]] = 1\n",
    "    return results    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c46c2b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = encoding(train_csv[\"Sequence\"])     # 112000*21 ndarray\n",
    "predict_x = encoding(predict_csv[\"Sequence\"]) #  48000*21 ndarray\n",
    "# labels\n",
    "train_y = train_csv[\"Active\"].values          # 112000*1 ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "88afe0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "test_split_ratio = 0.2\n",
    "zero_weight = 0.2\n",
    "input_nodes = 84\n",
    "hidden_nodes = 64\n",
    "output_nodes = 1\n",
    "dropout = 0.5\n",
    "EPOCHS = 150\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ad9186bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size=test_split_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7d628d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard scaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_predict = scaler.transform(predict_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dcca720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data structure\n",
    "class trainData(Dataset):\n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "## test data    \n",
    "class testData(Dataset):\n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "67e5faaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# package data for NN\n",
    "train_data = trainData(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n",
    "test_data = testData(torch.FloatTensor(X_test))\n",
    "predict_data = testData(torch.FloatTensor(X_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8f2ccca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[86208  3392]\n",
      "tensor([0.2000, 0.2000, 0.2000,  ..., 0.2000, 0.2000, 0.2000],\n",
      "       dtype=torch.float64)\n",
      "batch index 0, 0/1: 66/62\n",
      "batch index 1, 0/1: 61/67\n",
      "batch index 2, 0/1: 58/70\n",
      "batch index 3, 0/1: 72/56\n",
      "batch index 4, 0/1: 69/59\n",
      "batch index 5, 0/1: 74/54\n",
      "batch index 6, 0/1: 66/62\n",
      "batch index 7, 0/1: 62/66\n",
      "batch index 8, 0/1: 70/58\n",
      "batch index 9, 0/1: 71/57\n",
      "batch index 10, 0/1: 66/62\n",
      "batch index 11, 0/1: 75/53\n",
      "batch index 12, 0/1: 62/66\n",
      "batch index 13, 0/1: 72/56\n",
      "batch index 14, 0/1: 68/60\n",
      "batch index 15, 0/1: 65/63\n",
      "batch index 16, 0/1: 63/65\n",
      "batch index 17, 0/1: 73/55\n",
      "batch index 18, 0/1: 62/66\n",
      "batch index 19, 0/1: 74/54\n",
      "batch index 20, 0/1: 67/61\n",
      "batch index 21, 0/1: 54/74\n",
      "batch index 22, 0/1: 62/66\n",
      "batch index 23, 0/1: 72/56\n",
      "batch index 24, 0/1: 52/76\n",
      "batch index 25, 0/1: 58/70\n",
      "batch index 26, 0/1: 63/65\n",
      "batch index 27, 0/1: 57/71\n",
      "batch index 28, 0/1: 61/67\n",
      "batch index 29, 0/1: 69/59\n",
      "batch index 30, 0/1: 76/52\n",
      "batch index 31, 0/1: 65/63\n",
      "batch index 32, 0/1: 63/65\n",
      "batch index 33, 0/1: 67/61\n",
      "batch index 34, 0/1: 73/55\n",
      "batch index 35, 0/1: 63/65\n",
      "batch index 36, 0/1: 65/63\n",
      "batch index 37, 0/1: 46/82\n",
      "batch index 38, 0/1: 59/69\n",
      "batch index 39, 0/1: 64/64\n",
      "batch index 40, 0/1: 59/69\n",
      "batch index 41, 0/1: 60/68\n",
      "batch index 42, 0/1: 71/57\n",
      "batch index 43, 0/1: 64/64\n",
      "batch index 44, 0/1: 69/59\n",
      "batch index 45, 0/1: 61/67\n",
      "batch index 46, 0/1: 64/64\n",
      "batch index 47, 0/1: 66/62\n",
      "batch index 48, 0/1: 68/60\n",
      "batch index 49, 0/1: 70/58\n",
      "batch index 50, 0/1: 64/64\n",
      "batch index 51, 0/1: 64/64\n",
      "batch index 52, 0/1: 68/60\n",
      "batch index 53, 0/1: 53/75\n",
      "batch index 54, 0/1: 74/54\n",
      "batch index 55, 0/1: 69/59\n",
      "batch index 56, 0/1: 69/59\n",
      "batch index 57, 0/1: 66/62\n",
      "batch index 58, 0/1: 74/54\n",
      "batch index 59, 0/1: 68/60\n",
      "batch index 60, 0/1: 69/59\n",
      "batch index 61, 0/1: 55/73\n",
      "batch index 62, 0/1: 53/75\n",
      "batch index 63, 0/1: 70/58\n",
      "batch index 64, 0/1: 59/69\n",
      "batch index 65, 0/1: 72/56\n",
      "batch index 66, 0/1: 69/59\n",
      "batch index 67, 0/1: 65/63\n",
      "batch index 68, 0/1: 57/71\n",
      "batch index 69, 0/1: 56/72\n",
      "batch index 70, 0/1: 61/67\n",
      "batch index 71, 0/1: 64/64\n",
      "batch index 72, 0/1: 63/65\n",
      "batch index 73, 0/1: 58/70\n",
      "batch index 74, 0/1: 66/62\n",
      "batch index 75, 0/1: 70/58\n",
      "batch index 76, 0/1: 71/57\n",
      "batch index 77, 0/1: 62/66\n",
      "batch index 78, 0/1: 72/56\n",
      "batch index 79, 0/1: 63/65\n",
      "batch index 80, 0/1: 62/66\n",
      "batch index 81, 0/1: 58/70\n",
      "batch index 82, 0/1: 72/56\n",
      "batch index 83, 0/1: 58/70\n",
      "batch index 84, 0/1: 59/69\n",
      "batch index 85, 0/1: 64/64\n",
      "batch index 86, 0/1: 73/55\n",
      "batch index 87, 0/1: 67/61\n",
      "batch index 88, 0/1: 60/68\n",
      "batch index 89, 0/1: 63/65\n",
      "batch index 90, 0/1: 64/64\n",
      "batch index 91, 0/1: 61/67\n",
      "batch index 92, 0/1: 57/71\n",
      "batch index 93, 0/1: 58/70\n",
      "batch index 94, 0/1: 66/62\n",
      "batch index 95, 0/1: 71/57\n",
      "batch index 96, 0/1: 59/69\n",
      "batch index 97, 0/1: 56/72\n",
      "batch index 98, 0/1: 76/52\n",
      "batch index 99, 0/1: 58/70\n",
      "batch index 100, 0/1: 63/65\n",
      "batch index 101, 0/1: 61/67\n",
      "batch index 102, 0/1: 64/64\n",
      "batch index 103, 0/1: 71/57\n",
      "batch index 104, 0/1: 62/66\n",
      "batch index 105, 0/1: 66/62\n",
      "batch index 106, 0/1: 70/58\n",
      "batch index 107, 0/1: 55/73\n",
      "batch index 108, 0/1: 61/67\n",
      "batch index 109, 0/1: 68/60\n",
      "batch index 110, 0/1: 60/68\n",
      "batch index 111, 0/1: 63/65\n",
      "batch index 112, 0/1: 66/62\n",
      "batch index 113, 0/1: 63/65\n",
      "batch index 114, 0/1: 75/53\n",
      "batch index 115, 0/1: 59/69\n",
      "batch index 116, 0/1: 72/56\n",
      "batch index 117, 0/1: 50/78\n",
      "batch index 118, 0/1: 62/66\n",
      "batch index 119, 0/1: 58/70\n",
      "batch index 120, 0/1: 60/68\n",
      "batch index 121, 0/1: 62/66\n",
      "batch index 122, 0/1: 57/71\n",
      "batch index 123, 0/1: 52/76\n",
      "batch index 124, 0/1: 66/62\n",
      "batch index 125, 0/1: 55/73\n",
      "batch index 126, 0/1: 76/52\n",
      "batch index 127, 0/1: 63/65\n",
      "batch index 128, 0/1: 59/69\n",
      "batch index 129, 0/1: 65/63\n",
      "batch index 130, 0/1: 52/76\n",
      "batch index 131, 0/1: 62/66\n",
      "batch index 132, 0/1: 61/67\n",
      "batch index 133, 0/1: 59/69\n",
      "batch index 134, 0/1: 79/49\n",
      "batch index 135, 0/1: 54/74\n",
      "batch index 136, 0/1: 63/65\n",
      "batch index 137, 0/1: 68/60\n",
      "batch index 138, 0/1: 76/52\n",
      "batch index 139, 0/1: 74/54\n",
      "batch index 140, 0/1: 65/63\n",
      "batch index 141, 0/1: 64/64\n",
      "batch index 142, 0/1: 73/55\n",
      "batch index 143, 0/1: 65/63\n",
      "batch index 144, 0/1: 63/65\n",
      "batch index 145, 0/1: 73/55\n",
      "batch index 146, 0/1: 56/72\n",
      "batch index 147, 0/1: 66/62\n",
      "batch index 148, 0/1: 69/59\n",
      "batch index 149, 0/1: 59/69\n",
      "batch index 150, 0/1: 63/65\n",
      "batch index 151, 0/1: 77/51\n",
      "batch index 152, 0/1: 61/67\n",
      "batch index 153, 0/1: 73/55\n",
      "batch index 154, 0/1: 55/73\n",
      "batch index 155, 0/1: 70/58\n",
      "batch index 156, 0/1: 59/69\n",
      "batch index 157, 0/1: 65/63\n",
      "batch index 158, 0/1: 72/56\n",
      "batch index 159, 0/1: 69/59\n",
      "batch index 160, 0/1: 69/59\n",
      "batch index 161, 0/1: 60/68\n",
      "batch index 162, 0/1: 62/66\n",
      "batch index 163, 0/1: 53/75\n",
      "batch index 164, 0/1: 62/66\n",
      "batch index 165, 0/1: 61/67\n",
      "batch index 166, 0/1: 62/66\n",
      "batch index 167, 0/1: 67/61\n",
      "batch index 168, 0/1: 63/65\n",
      "batch index 169, 0/1: 71/57\n",
      "batch index 170, 0/1: 57/71\n",
      "batch index 171, 0/1: 62/66\n",
      "batch index 172, 0/1: 57/71\n",
      "batch index 173, 0/1: 66/62\n",
      "batch index 174, 0/1: 64/64\n",
      "batch index 175, 0/1: 65/63\n",
      "batch index 176, 0/1: 58/70\n",
      "batch index 177, 0/1: 67/61\n",
      "batch index 178, 0/1: 67/61\n",
      "batch index 179, 0/1: 55/73\n",
      "batch index 180, 0/1: 73/55\n",
      "batch index 181, 0/1: 67/61\n",
      "batch index 182, 0/1: 57/71\n",
      "batch index 183, 0/1: 67/61\n",
      "batch index 184, 0/1: 59/69\n",
      "batch index 185, 0/1: 71/57\n",
      "batch index 186, 0/1: 68/60\n",
      "batch index 187, 0/1: 61/67\n",
      "batch index 188, 0/1: 69/59\n",
      "batch index 189, 0/1: 58/70\n",
      "batch index 190, 0/1: 65/63\n",
      "batch index 191, 0/1: 70/58\n",
      "batch index 192, 0/1: 67/61\n",
      "batch index 193, 0/1: 70/58\n",
      "batch index 194, 0/1: 63/65\n",
      "batch index 195, 0/1: 63/65\n",
      "batch index 196, 0/1: 58/70\n",
      "batch index 197, 0/1: 69/59\n",
      "batch index 198, 0/1: 66/62\n",
      "batch index 199, 0/1: 54/74\n",
      "batch index 200, 0/1: 66/62\n",
      "batch index 201, 0/1: 66/62\n",
      "batch index 202, 0/1: 59/69\n",
      "batch index 203, 0/1: 60/68\n",
      "batch index 204, 0/1: 67/61\n",
      "batch index 205, 0/1: 65/63\n",
      "batch index 206, 0/1: 49/79\n",
      "batch index 207, 0/1: 60/68\n",
      "batch index 208, 0/1: 66/62\n",
      "batch index 209, 0/1: 61/67\n",
      "batch index 210, 0/1: 63/65\n",
      "batch index 211, 0/1: 63/65\n",
      "batch index 212, 0/1: 72/56\n",
      "batch index 213, 0/1: 60/68\n",
      "batch index 214, 0/1: 67/61\n",
      "batch index 215, 0/1: 57/71\n",
      "batch index 216, 0/1: 63/65\n",
      "batch index 217, 0/1: 60/68\n",
      "batch index 218, 0/1: 67/61\n",
      "batch index 219, 0/1: 69/59\n",
      "batch index 220, 0/1: 73/55\n",
      "batch index 221, 0/1: 55/73\n",
      "batch index 222, 0/1: 72/56\n",
      "batch index 223, 0/1: 67/61\n",
      "batch index 224, 0/1: 64/64\n",
      "batch index 225, 0/1: 67/61\n",
      "batch index 226, 0/1: 60/68\n",
      "batch index 227, 0/1: 60/68\n",
      "batch index 228, 0/1: 56/72\n",
      "batch index 229, 0/1: 59/69\n",
      "batch index 230, 0/1: 57/71\n",
      "batch index 231, 0/1: 68/60\n",
      "batch index 232, 0/1: 71/57\n",
      "batch index 233, 0/1: 65/63\n",
      "batch index 234, 0/1: 68/60\n",
      "batch index 235, 0/1: 75/53\n",
      "batch index 236, 0/1: 76/52\n",
      "batch index 237, 0/1: 71/57\n",
      "batch index 238, 0/1: 66/62\n",
      "batch index 239, 0/1: 70/58\n",
      "batch index 240, 0/1: 58/70\n",
      "batch index 241, 0/1: 76/52\n",
      "batch index 242, 0/1: 57/71\n",
      "batch index 243, 0/1: 61/67\n",
      "batch index 244, 0/1: 60/68\n",
      "batch index 245, 0/1: 56/72\n",
      "batch index 246, 0/1: 67/61\n",
      "batch index 247, 0/1: 66/62\n",
      "batch index 248, 0/1: 66/62\n",
      "batch index 249, 0/1: 64/64\n",
      "batch index 250, 0/1: 52/76\n",
      "batch index 251, 0/1: 71/57\n",
      "batch index 252, 0/1: 61/67\n",
      "batch index 253, 0/1: 62/66\n",
      "batch index 254, 0/1: 69/59\n",
      "batch index 255, 0/1: 61/67\n",
      "batch index 256, 0/1: 60/68\n",
      "batch index 257, 0/1: 60/68\n",
      "batch index 258, 0/1: 63/65\n",
      "batch index 259, 0/1: 74/54\n",
      "batch index 260, 0/1: 64/64\n",
      "batch index 261, 0/1: 68/60\n",
      "batch index 262, 0/1: 67/61\n",
      "batch index 263, 0/1: 67/61\n",
      "batch index 264, 0/1: 63/65\n",
      "batch index 265, 0/1: 64/64\n",
      "batch index 266, 0/1: 63/65\n",
      "batch index 267, 0/1: 69/59\n",
      "batch index 268, 0/1: 65/63\n",
      "batch index 269, 0/1: 60/68\n",
      "batch index 270, 0/1: 59/69\n",
      "batch index 271, 0/1: 60/68\n",
      "batch index 272, 0/1: 61/67\n",
      "batch index 273, 0/1: 59/69\n",
      "batch index 274, 0/1: 67/61\n",
      "batch index 275, 0/1: 64/64\n",
      "batch index 276, 0/1: 69/59\n",
      "batch index 277, 0/1: 61/67\n",
      "batch index 278, 0/1: 55/73\n",
      "batch index 279, 0/1: 66/62\n",
      "batch index 280, 0/1: 71/57\n",
      "batch index 281, 0/1: 64/64\n",
      "batch index 282, 0/1: 57/71\n",
      "batch index 283, 0/1: 65/63\n",
      "batch index 284, 0/1: 55/73\n",
      "batch index 285, 0/1: 71/57\n",
      "batch index 286, 0/1: 60/68\n",
      "batch index 287, 0/1: 68/60\n",
      "batch index 288, 0/1: 69/59\n",
      "batch index 289, 0/1: 66/62\n",
      "batch index 290, 0/1: 66/62\n",
      "batch index 291, 0/1: 72/56\n",
      "batch index 292, 0/1: 75/53\n",
      "batch index 293, 0/1: 72/56\n",
      "batch index 294, 0/1: 65/63\n",
      "batch index 295, 0/1: 63/65\n",
      "batch index 296, 0/1: 57/71\n",
      "batch index 297, 0/1: 61/67\n",
      "batch index 298, 0/1: 68/60\n",
      "batch index 299, 0/1: 74/54\n",
      "batch index 300, 0/1: 62/66\n",
      "batch index 301, 0/1: 58/70\n",
      "batch index 302, 0/1: 53/75\n",
      "batch index 303, 0/1: 68/60\n",
      "batch index 304, 0/1: 62/66\n",
      "batch index 305, 0/1: 64/64\n",
      "batch index 306, 0/1: 57/71\n",
      "batch index 307, 0/1: 65/63\n",
      "batch index 308, 0/1: 56/72\n",
      "batch index 309, 0/1: 73/55\n",
      "batch index 310, 0/1: 63/65\n",
      "batch index 311, 0/1: 57/71\n",
      "batch index 312, 0/1: 62/66\n",
      "batch index 313, 0/1: 56/72\n",
      "batch index 314, 0/1: 62/66\n",
      "batch index 315, 0/1: 61/67\n",
      "batch index 316, 0/1: 65/63\n",
      "batch index 317, 0/1: 69/59\n",
      "batch index 318, 0/1: 59/69\n",
      "batch index 319, 0/1: 58/70\n",
      "batch index 320, 0/1: 63/65\n",
      "batch index 321, 0/1: 55/73\n",
      "batch index 322, 0/1: 82/46\n",
      "batch index 323, 0/1: 62/66\n",
      "batch index 324, 0/1: 62/66\n",
      "batch index 325, 0/1: 70/58\n",
      "batch index 326, 0/1: 75/53\n",
      "batch index 327, 0/1: 66/62\n",
      "batch index 328, 0/1: 63/65\n",
      "batch index 329, 0/1: 63/65\n",
      "batch index 330, 0/1: 72/56\n",
      "batch index 331, 0/1: 72/56\n",
      "batch index 332, 0/1: 65/63\n",
      "batch index 333, 0/1: 64/64\n",
      "batch index 334, 0/1: 63/65\n",
      "batch index 335, 0/1: 56/72\n",
      "batch index 336, 0/1: 56/72\n",
      "batch index 337, 0/1: 62/66\n",
      "batch index 338, 0/1: 66/62\n",
      "batch index 339, 0/1: 59/69\n",
      "batch index 340, 0/1: 65/63\n",
      "batch index 341, 0/1: 58/70\n",
      "batch index 342, 0/1: 63/65\n",
      "batch index 343, 0/1: 66/62\n",
      "batch index 344, 0/1: 55/73\n",
      "batch index 345, 0/1: 67/61\n",
      "batch index 346, 0/1: 64/64\n",
      "batch index 347, 0/1: 70/58\n",
      "batch index 348, 0/1: 62/66\n",
      "batch index 349, 0/1: 76/52\n",
      "batch index 350, 0/1: 68/60\n",
      "batch index 351, 0/1: 64/64\n",
      "batch index 352, 0/1: 72/56\n",
      "batch index 353, 0/1: 65/63\n",
      "batch index 354, 0/1: 59/69\n",
      "batch index 355, 0/1: 66/62\n",
      "batch index 356, 0/1: 60/68\n",
      "batch index 357, 0/1: 58/70\n",
      "batch index 358, 0/1: 63/65\n",
      "batch index 359, 0/1: 66/62\n",
      "batch index 360, 0/1: 63/65\n",
      "batch index 361, 0/1: 61/67\n",
      "batch index 362, 0/1: 64/64\n",
      "batch index 363, 0/1: 70/58\n",
      "batch index 364, 0/1: 57/71\n",
      "batch index 365, 0/1: 63/65\n",
      "batch index 366, 0/1: 59/69\n",
      "batch index 367, 0/1: 65/63\n",
      "batch index 368, 0/1: 68/60\n",
      "batch index 369, 0/1: 63/65\n",
      "batch index 370, 0/1: 59/69\n",
      "batch index 371, 0/1: 56/72\n",
      "batch index 372, 0/1: 60/68\n",
      "batch index 373, 0/1: 68/60\n",
      "batch index 374, 0/1: 72/56\n",
      "batch index 375, 0/1: 61/67\n",
      "batch index 376, 0/1: 57/71\n",
      "batch index 377, 0/1: 64/64\n",
      "batch index 378, 0/1: 63/65\n",
      "batch index 379, 0/1: 62/66\n",
      "batch index 380, 0/1: 52/76\n",
      "batch index 381, 0/1: 61/67\n",
      "batch index 382, 0/1: 71/57\n",
      "batch index 383, 0/1: 60/68\n",
      "batch index 384, 0/1: 63/65\n",
      "batch index 385, 0/1: 58/70\n",
      "batch index 386, 0/1: 72/56\n",
      "batch index 387, 0/1: 66/62\n",
      "batch index 388, 0/1: 58/70\n",
      "batch index 389, 0/1: 57/71\n",
      "batch index 390, 0/1: 63/65\n",
      "batch index 391, 0/1: 63/65\n",
      "batch index 392, 0/1: 58/70\n",
      "batch index 393, 0/1: 69/59\n",
      "batch index 394, 0/1: 69/59\n",
      "batch index 395, 0/1: 66/62\n",
      "batch index 396, 0/1: 62/66\n",
      "batch index 397, 0/1: 64/64\n",
      "batch index 398, 0/1: 59/69\n",
      "batch index 399, 0/1: 74/54\n",
      "batch index 400, 0/1: 66/62\n",
      "batch index 401, 0/1: 47/81\n",
      "batch index 402, 0/1: 52/76\n",
      "batch index 403, 0/1: 69/59\n",
      "batch index 404, 0/1: 64/64\n",
      "batch index 405, 0/1: 63/65\n",
      "batch index 406, 0/1: 69/59\n",
      "batch index 407, 0/1: 69/59\n",
      "batch index 408, 0/1: 72/56\n",
      "batch index 409, 0/1: 66/62\n",
      "batch index 410, 0/1: 64/64\n",
      "batch index 411, 0/1: 60/68\n",
      "batch index 412, 0/1: 71/57\n",
      "batch index 413, 0/1: 58/70\n",
      "batch index 414, 0/1: 62/66\n",
      "batch index 415, 0/1: 63/65\n",
      "batch index 416, 0/1: 78/50\n",
      "batch index 417, 0/1: 62/66\n",
      "batch index 418, 0/1: 69/59\n",
      "batch index 419, 0/1: 73/55\n",
      "batch index 420, 0/1: 68/60\n",
      "batch index 421, 0/1: 57/71\n",
      "batch index 422, 0/1: 62/66\n",
      "batch index 423, 0/1: 60/68\n",
      "batch index 424, 0/1: 58/70\n",
      "batch index 425, 0/1: 72/56\n",
      "batch index 426, 0/1: 63/65\n",
      "batch index 427, 0/1: 59/69\n",
      "batch index 428, 0/1: 63/65\n",
      "batch index 429, 0/1: 66/62\n",
      "batch index 430, 0/1: 66/62\n",
      "batch index 431, 0/1: 66/62\n",
      "batch index 432, 0/1: 68/60\n",
      "batch index 433, 0/1: 65/63\n",
      "batch index 434, 0/1: 56/72\n",
      "batch index 435, 0/1: 64/64\n",
      "batch index 436, 0/1: 75/53\n",
      "batch index 437, 0/1: 63/65\n",
      "batch index 438, 0/1: 65/63\n",
      "batch index 439, 0/1: 77/51\n",
      "batch index 440, 0/1: 46/82\n",
      "batch index 441, 0/1: 59/69\n",
      "batch index 442, 0/1: 60/68\n",
      "batch index 443, 0/1: 64/64\n",
      "batch index 444, 0/1: 63/65\n",
      "batch index 445, 0/1: 78/50\n",
      "batch index 446, 0/1: 49/79\n",
      "batch index 447, 0/1: 67/61\n",
      "batch index 448, 0/1: 62/66\n",
      "batch index 449, 0/1: 55/73\n",
      "batch index 450, 0/1: 70/58\n",
      "batch index 451, 0/1: 65/63\n",
      "batch index 452, 0/1: 67/61\n",
      "batch index 453, 0/1: 70/58\n",
      "batch index 454, 0/1: 70/58\n",
      "batch index 455, 0/1: 72/56\n",
      "batch index 456, 0/1: 66/62\n",
      "batch index 457, 0/1: 64/64\n",
      "batch index 458, 0/1: 55/73\n",
      "batch index 459, 0/1: 69/59\n",
      "batch index 460, 0/1: 64/64\n",
      "batch index 461, 0/1: 78/50\n",
      "batch index 462, 0/1: 60/68\n",
      "batch index 463, 0/1: 71/57\n",
      "batch index 464, 0/1: 78/50\n",
      "batch index 465, 0/1: 68/60\n",
      "batch index 466, 0/1: 72/56\n",
      "batch index 467, 0/1: 58/70\n",
      "batch index 468, 0/1: 67/61\n",
      "batch index 469, 0/1: 61/67\n",
      "batch index 470, 0/1: 58/70\n",
      "batch index 471, 0/1: 65/63\n",
      "batch index 472, 0/1: 58/70\n",
      "batch index 473, 0/1: 68/60\n",
      "batch index 474, 0/1: 70/58\n",
      "batch index 475, 0/1: 63/65\n",
      "batch index 476, 0/1: 54/74\n",
      "batch index 477, 0/1: 66/62\n",
      "batch index 478, 0/1: 63/65\n",
      "batch index 479, 0/1: 62/66\n",
      "batch index 480, 0/1: 71/57\n",
      "batch index 481, 0/1: 68/60\n",
      "batch index 482, 0/1: 66/62\n",
      "batch index 483, 0/1: 59/69\n",
      "batch index 484, 0/1: 69/59\n",
      "batch index 485, 0/1: 73/55\n",
      "batch index 486, 0/1: 68/60\n",
      "batch index 487, 0/1: 59/69\n",
      "batch index 488, 0/1: 70/58\n",
      "batch index 489, 0/1: 67/61\n",
      "batch index 490, 0/1: 55/73\n",
      "batch index 491, 0/1: 63/65\n",
      "batch index 492, 0/1: 59/69\n",
      "batch index 493, 0/1: 58/70\n",
      "batch index 494, 0/1: 60/68\n",
      "batch index 495, 0/1: 59/69\n",
      "batch index 496, 0/1: 65/63\n",
      "batch index 497, 0/1: 71/57\n",
      "batch index 498, 0/1: 66/62\n",
      "batch index 499, 0/1: 59/69\n",
      "batch index 500, 0/1: 75/53\n",
      "batch index 501, 0/1: 63/65\n",
      "batch index 502, 0/1: 72/56\n",
      "batch index 503, 0/1: 57/71\n",
      "batch index 504, 0/1: 59/69\n",
      "batch index 505, 0/1: 56/72\n",
      "batch index 506, 0/1: 63/65\n",
      "batch index 507, 0/1: 70/58\n",
      "batch index 508, 0/1: 67/61\n",
      "batch index 509, 0/1: 61/67\n",
      "batch index 510, 0/1: 69/59\n",
      "batch index 511, 0/1: 57/71\n",
      "batch index 512, 0/1: 75/53\n",
      "batch index 513, 0/1: 71/57\n",
      "batch index 514, 0/1: 71/57\n",
      "batch index 515, 0/1: 65/63\n",
      "batch index 516, 0/1: 64/64\n",
      "batch index 517, 0/1: 51/77\n",
      "batch index 518, 0/1: 63/65\n",
      "batch index 519, 0/1: 60/68\n",
      "batch index 520, 0/1: 60/68\n",
      "batch index 521, 0/1: 71/57\n",
      "batch index 522, 0/1: 67/61\n",
      "batch index 523, 0/1: 63/65\n",
      "batch index 524, 0/1: 69/59\n",
      "batch index 525, 0/1: 57/71\n",
      "batch index 526, 0/1: 63/65\n",
      "batch index 527, 0/1: 77/51\n",
      "batch index 528, 0/1: 66/62\n",
      "batch index 529, 0/1: 73/55\n",
      "batch index 530, 0/1: 64/64\n",
      "batch index 531, 0/1: 75/53\n",
      "batch index 532, 0/1: 67/61\n",
      "batch index 533, 0/1: 58/70\n",
      "batch index 534, 0/1: 67/61\n",
      "batch index 535, 0/1: 59/69\n",
      "batch index 536, 0/1: 61/67\n",
      "batch index 537, 0/1: 64/64\n",
      "batch index 538, 0/1: 56/72\n",
      "batch index 539, 0/1: 63/65\n",
      "batch index 540, 0/1: 61/67\n",
      "batch index 541, 0/1: 67/61\n",
      "batch index 542, 0/1: 64/64\n",
      "batch index 543, 0/1: 61/67\n",
      "batch index 544, 0/1: 64/64\n",
      "batch index 545, 0/1: 68/60\n",
      "batch index 546, 0/1: 70/58\n",
      "batch index 547, 0/1: 57/71\n",
      "batch index 548, 0/1: 59/69\n",
      "batch index 549, 0/1: 66/62\n",
      "batch index 550, 0/1: 72/56\n",
      "batch index 551, 0/1: 58/70\n",
      "batch index 552, 0/1: 69/59\n",
      "batch index 553, 0/1: 54/74\n",
      "batch index 554, 0/1: 59/69\n",
      "batch index 555, 0/1: 61/67\n",
      "batch index 556, 0/1: 63/65\n",
      "batch index 557, 0/1: 60/68\n",
      "batch index 558, 0/1: 64/64\n",
      "batch index 559, 0/1: 67/61\n",
      "batch index 560, 0/1: 69/59\n",
      "batch index 561, 0/1: 72/56\n",
      "batch index 562, 0/1: 65/63\n",
      "batch index 563, 0/1: 67/61\n",
      "batch index 564, 0/1: 66/62\n",
      "batch index 565, 0/1: 64/64\n",
      "batch index 566, 0/1: 60/68\n",
      "batch index 567, 0/1: 63/65\n",
      "batch index 568, 0/1: 65/63\n",
      "batch index 569, 0/1: 60/68\n",
      "batch index 570, 0/1: 64/64\n",
      "batch index 571, 0/1: 57/71\n",
      "batch index 572, 0/1: 67/61\n",
      "batch index 573, 0/1: 59/69\n",
      "batch index 574, 0/1: 66/62\n",
      "batch index 575, 0/1: 65/63\n",
      "batch index 576, 0/1: 44/84\n",
      "batch index 577, 0/1: 69/59\n",
      "batch index 578, 0/1: 66/62\n",
      "batch index 579, 0/1: 71/57\n",
      "batch index 580, 0/1: 62/66\n",
      "batch index 581, 0/1: 65/63\n",
      "batch index 582, 0/1: 69/59\n",
      "batch index 583, 0/1: 66/62\n",
      "batch index 584, 0/1: 66/62\n",
      "batch index 585, 0/1: 62/66\n",
      "batch index 586, 0/1: 66/62\n",
      "batch index 587, 0/1: 62/66\n",
      "batch index 588, 0/1: 71/57\n",
      "batch index 589, 0/1: 69/59\n",
      "batch index 590, 0/1: 66/62\n",
      "batch index 591, 0/1: 67/61\n",
      "batch index 592, 0/1: 66/62\n",
      "batch index 593, 0/1: 63/65\n",
      "batch index 594, 0/1: 72/56\n",
      "batch index 595, 0/1: 67/61\n",
      "batch index 596, 0/1: 68/60\n",
      "batch index 597, 0/1: 66/62\n",
      "batch index 598, 0/1: 71/57\n",
      "batch index 599, 0/1: 64/64\n",
      "batch index 600, 0/1: 63/65\n",
      "batch index 601, 0/1: 65/63\n",
      "batch index 602, 0/1: 63/65\n",
      "batch index 603, 0/1: 65/63\n",
      "batch index 604, 0/1: 67/61\n",
      "batch index 605, 0/1: 64/64\n",
      "batch index 606, 0/1: 63/65\n",
      "batch index 607, 0/1: 66/62\n",
      "batch index 608, 0/1: 69/59\n",
      "batch index 609, 0/1: 67/61\n",
      "batch index 610, 0/1: 65/63\n",
      "batch index 611, 0/1: 66/62\n",
      "batch index 612, 0/1: 57/71\n",
      "batch index 613, 0/1: 72/56\n",
      "batch index 614, 0/1: 66/62\n",
      "batch index 615, 0/1: 52/76\n",
      "batch index 616, 0/1: 67/61\n",
      "batch index 617, 0/1: 61/67\n",
      "batch index 618, 0/1: 74/54\n",
      "batch index 619, 0/1: 62/66\n",
      "batch index 620, 0/1: 72/56\n",
      "batch index 621, 0/1: 71/57\n",
      "batch index 622, 0/1: 73/55\n",
      "batch index 623, 0/1: 56/72\n",
      "batch index 624, 0/1: 72/56\n",
      "batch index 625, 0/1: 64/64\n",
      "batch index 626, 0/1: 71/57\n",
      "batch index 627, 0/1: 57/71\n",
      "batch index 628, 0/1: 65/63\n",
      "batch index 629, 0/1: 54/74\n",
      "batch index 630, 0/1: 53/75\n",
      "batch index 631, 0/1: 76/52\n",
      "batch index 632, 0/1: 55/73\n",
      "batch index 633, 0/1: 75/53\n",
      "batch index 634, 0/1: 62/66\n",
      "batch index 635, 0/1: 58/70\n",
      "batch index 636, 0/1: 65/63\n",
      "batch index 637, 0/1: 66/62\n",
      "batch index 638, 0/1: 68/60\n",
      "batch index 639, 0/1: 69/59\n",
      "batch index 640, 0/1: 66/62\n",
      "batch index 641, 0/1: 64/64\n",
      "batch index 642, 0/1: 62/66\n",
      "batch index 643, 0/1: 61/67\n",
      "batch index 644, 0/1: 62/66\n",
      "batch index 645, 0/1: 55/73\n",
      "batch index 646, 0/1: 71/57\n",
      "batch index 647, 0/1: 59/69\n",
      "batch index 648, 0/1: 70/58\n",
      "batch index 649, 0/1: 62/66\n",
      "batch index 650, 0/1: 60/68\n",
      "batch index 651, 0/1: 58/70\n",
      "batch index 652, 0/1: 67/61\n",
      "batch index 653, 0/1: 62/66\n",
      "batch index 654, 0/1: 66/62\n",
      "batch index 655, 0/1: 70/58\n",
      "batch index 656, 0/1: 65/63\n",
      "batch index 657, 0/1: 62/66\n",
      "batch index 658, 0/1: 62/66\n",
      "batch index 659, 0/1: 67/61\n",
      "batch index 660, 0/1: 76/52\n",
      "batch index 661, 0/1: 68/60\n",
      "batch index 662, 0/1: 73/55\n",
      "batch index 663, 0/1: 74/54\n",
      "batch index 664, 0/1: 60/68\n",
      "batch index 665, 0/1: 65/63\n",
      "batch index 666, 0/1: 61/67\n",
      "batch index 667, 0/1: 74/54\n",
      "batch index 668, 0/1: 72/56\n",
      "batch index 669, 0/1: 73/55\n",
      "batch index 670, 0/1: 65/63\n",
      "batch index 671, 0/1: 59/69\n",
      "batch index 672, 0/1: 70/58\n",
      "batch index 673, 0/1: 56/72\n",
      "batch index 674, 0/1: 61/67\n",
      "batch index 675, 0/1: 63/65\n",
      "batch index 676, 0/1: 58/70\n",
      "batch index 677, 0/1: 65/63\n",
      "batch index 678, 0/1: 65/63\n",
      "batch index 679, 0/1: 69/59\n",
      "batch index 680, 0/1: 70/58\n",
      "batch index 681, 0/1: 65/63\n",
      "batch index 682, 0/1: 61/67\n",
      "batch index 683, 0/1: 64/64\n",
      "batch index 684, 0/1: 62/66\n",
      "batch index 685, 0/1: 61/67\n",
      "batch index 686, 0/1: 59/69\n",
      "batch index 687, 0/1: 72/56\n",
      "batch index 688, 0/1: 75/53\n",
      "batch index 689, 0/1: 63/65\n",
      "batch index 690, 0/1: 65/63\n",
      "batch index 691, 0/1: 65/63\n",
      "batch index 692, 0/1: 66/62\n",
      "batch index 693, 0/1: 63/65\n",
      "batch index 694, 0/1: 59/69\n",
      "batch index 695, 0/1: 59/69\n",
      "batch index 696, 0/1: 69/59\n",
      "batch index 697, 0/1: 66/62\n",
      "batch index 698, 0/1: 65/63\n",
      "batch index 699, 0/1: 67/61\n"
     ]
    }
   ],
   "source": [
    "# for imbalanced dataset\n",
    "class_count = np.array([len(np.where(y_train == t)[0]) for t in range(2)])    # return num of 0s and 1s\n",
    "weight = [zero_weight, 1.0/zero_weight]                                                     # define weight\n",
    "samples_weight = np.array([weight[t] for t in y_train])                                     # give weight for EACH data sample\n",
    "samples_weight = torch.from_numpy(samples_weight).double()                                  # turn to torch (double)\n",
    "Sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, sampler=Sampler)\n",
    "\n",
    "test_loader = DataLoader(test_data)\n",
    "predict_loader = DataLoader(predict_data)\n",
    "\n",
    "print(class_count)\n",
    "print(samples_weight)\n",
    "for i, (data, target) in enumerate(train_loader):\n",
    "    print( \"batch index {}, 0/1: {}/{}\".format(i,len(np.where(target.numpy() == 0)[0]),len(np.where(target.numpy() == 1)[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d07e0785",
   "metadata": {},
   "outputs": [],
   "source": [
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        # Number of input features is 21.\n",
    "        self.layer_1 = nn.Linear(input_nodes, hidden_nodes) \n",
    "        self.layer_2 = nn.Linear(hidden_nodes, hidden_nodes)\n",
    "        self.layer_out = nn.Linear(hidden_nodes, output_nodes) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(hidden_nodes)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(hidden_nodes)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3d170bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9b5500f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = binaryClassification()\n",
    "model.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4e45b3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1dc6ea61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.18877 | Acc: 92.964\n",
      "Epoch 002: | Loss: 0.08044 | Acc: 97.330\n",
      "Epoch 003: | Loss: 0.05492 | Acc: 98.113\n",
      "Epoch 004: | Loss: 0.04640 | Acc: 98.413\n",
      "Epoch 005: | Loss: 0.04052 | Acc: 98.607\n",
      "Epoch 006: | Loss: 0.03636 | Acc: 98.743\n",
      "Epoch 007: | Loss: 0.03215 | Acc: 98.861\n",
      "Epoch 008: | Loss: 0.03066 | Acc: 98.931\n",
      "Epoch 009: | Loss: 0.02776 | Acc: 99.014\n",
      "Epoch 010: | Loss: 0.02629 | Acc: 99.060\n",
      "Epoch 011: | Loss: 0.02524 | Acc: 99.091\n",
      "Epoch 012: | Loss: 0.02433 | Acc: 99.127\n",
      "Epoch 013: | Loss: 0.02355 | Acc: 99.173\n",
      "Epoch 014: | Loss: 0.02093 | Acc: 99.236\n",
      "Epoch 015: | Loss: 0.02061 | Acc: 99.244\n",
      "Epoch 016: | Loss: 0.02063 | Acc: 99.260\n",
      "Epoch 017: | Loss: 0.02121 | Acc: 99.241\n",
      "Epoch 018: | Loss: 0.01853 | Acc: 99.329\n",
      "Epoch 019: | Loss: 0.02127 | Acc: 99.230\n",
      "Epoch 020: | Loss: 0.01872 | Acc: 99.279\n",
      "Epoch 021: | Loss: 0.01749 | Acc: 99.360\n",
      "Epoch 022: | Loss: 0.01708 | Acc: 99.346\n",
      "Epoch 023: | Loss: 0.01645 | Acc: 99.391\n",
      "Epoch 024: | Loss: 0.01623 | Acc: 99.391\n",
      "Epoch 025: | Loss: 0.01558 | Acc: 99.411\n",
      "Epoch 026: | Loss: 0.01675 | Acc: 99.374\n",
      "Epoch 027: | Loss: 0.01446 | Acc: 99.464\n",
      "Epoch 028: | Loss: 0.01545 | Acc: 99.394\n",
      "Epoch 029: | Loss: 0.01391 | Acc: 99.473\n",
      "Epoch 030: | Loss: 0.01540 | Acc: 99.430\n",
      "Epoch 031: | Loss: 0.01362 | Acc: 99.493\n",
      "Epoch 032: | Loss: 0.01433 | Acc: 99.470\n",
      "Epoch 033: | Loss: 0.01313 | Acc: 99.496\n",
      "Epoch 034: | Loss: 0.01135 | Acc: 99.549\n",
      "Epoch 035: | Loss: 0.01401 | Acc: 99.457\n",
      "Epoch 036: | Loss: 0.01406 | Acc: 99.471\n",
      "Epoch 037: | Loss: 0.01143 | Acc: 99.587\n",
      "Epoch 038: | Loss: 0.01240 | Acc: 99.527\n",
      "Epoch 039: | Loss: 0.01156 | Acc: 99.559\n",
      "Epoch 040: | Loss: 0.01152 | Acc: 99.541\n",
      "Epoch 041: | Loss: 0.01187 | Acc: 99.580\n",
      "Epoch 042: | Loss: 0.01158 | Acc: 99.574\n",
      "Epoch 043: | Loss: 0.01121 | Acc: 99.553\n",
      "Epoch 044: | Loss: 0.01128 | Acc: 99.570\n",
      "Epoch 045: | Loss: 0.01116 | Acc: 99.567\n",
      "Epoch 046: | Loss: 0.00913 | Acc: 99.633\n",
      "Epoch 047: | Loss: 0.00986 | Acc: 99.587\n",
      "Epoch 048: | Loss: 0.01130 | Acc: 99.554\n",
      "Epoch 049: | Loss: 0.01027 | Acc: 99.604\n",
      "Epoch 050: | Loss: 0.01010 | Acc: 99.616\n",
      "Epoch 051: | Loss: 0.01061 | Acc: 99.576\n",
      "Epoch 052: | Loss: 0.00986 | Acc: 99.611\n",
      "Epoch 053: | Loss: 0.01022 | Acc: 99.620\n",
      "Epoch 054: | Loss: 0.00920 | Acc: 99.639\n",
      "Epoch 055: | Loss: 0.00919 | Acc: 99.627\n",
      "Epoch 056: | Loss: 0.00931 | Acc: 99.619\n",
      "Epoch 057: | Loss: 0.00839 | Acc: 99.664\n",
      "Epoch 058: | Loss: 0.00968 | Acc: 99.613\n",
      "Epoch 059: | Loss: 0.00882 | Acc: 99.650\n",
      "Epoch 060: | Loss: 0.00882 | Acc: 99.683\n",
      "Epoch 061: | Loss: 0.00858 | Acc: 99.671\n",
      "Epoch 062: | Loss: 0.00939 | Acc: 99.660\n",
      "Epoch 063: | Loss: 0.00839 | Acc: 99.663\n",
      "Epoch 064: | Loss: 0.00813 | Acc: 99.671\n",
      "Epoch 065: | Loss: 0.00812 | Acc: 99.677\n",
      "Epoch 066: | Loss: 0.00938 | Acc: 99.630\n",
      "Epoch 067: | Loss: 0.00887 | Acc: 99.664\n",
      "Epoch 068: | Loss: 0.00795 | Acc: 99.689\n",
      "Epoch 069: | Loss: 0.00788 | Acc: 99.701\n",
      "Epoch 070: | Loss: 0.00677 | Acc: 99.719\n",
      "Epoch 071: | Loss: 0.00846 | Acc: 99.663\n",
      "Epoch 072: | Loss: 0.00745 | Acc: 99.716\n",
      "Epoch 073: | Loss: 0.00854 | Acc: 99.623\n",
      "Epoch 074: | Loss: 0.00803 | Acc: 99.684\n",
      "Epoch 075: | Loss: 0.00830 | Acc: 99.651\n",
      "Epoch 076: | Loss: 0.00737 | Acc: 99.713\n",
      "Epoch 077: | Loss: 0.00634 | Acc: 99.759\n",
      "Epoch 078: | Loss: 0.00749 | Acc: 99.699\n",
      "Epoch 079: | Loss: 0.00786 | Acc: 99.691\n",
      "Epoch 080: | Loss: 0.00740 | Acc: 99.711\n",
      "Epoch 081: | Loss: 0.00622 | Acc: 99.751\n",
      "Epoch 082: | Loss: 0.00752 | Acc: 99.704\n",
      "Epoch 083: | Loss: 0.00694 | Acc: 99.727\n",
      "Epoch 084: | Loss: 0.00625 | Acc: 99.740\n",
      "Epoch 085: | Loss: 0.00615 | Acc: 99.770\n",
      "Epoch 086: | Loss: 0.00692 | Acc: 99.724\n",
      "Epoch 087: | Loss: 0.00632 | Acc: 99.763\n",
      "Epoch 088: | Loss: 0.00700 | Acc: 99.717\n",
      "Epoch 089: | Loss: 0.00722 | Acc: 99.716\n",
      "Epoch 090: | Loss: 0.00583 | Acc: 99.743\n",
      "Epoch 091: | Loss: 0.00681 | Acc: 99.710\n",
      "Epoch 092: | Loss: 0.00600 | Acc: 99.757\n",
      "Epoch 093: | Loss: 0.00603 | Acc: 99.770\n",
      "Epoch 094: | Loss: 0.00682 | Acc: 99.723\n",
      "Epoch 095: | Loss: 0.00592 | Acc: 99.771\n",
      "Epoch 096: | Loss: 0.00667 | Acc: 99.733\n",
      "Epoch 097: | Loss: 0.00602 | Acc: 99.759\n",
      "Epoch 098: | Loss: 0.00580 | Acc: 99.781\n",
      "Epoch 099: | Loss: 0.00554 | Acc: 99.761\n",
      "Epoch 100: | Loss: 0.00742 | Acc: 99.693\n",
      "Epoch 101: | Loss: 0.00568 | Acc: 99.786\n",
      "Epoch 102: | Loss: 0.00575 | Acc: 99.770\n",
      "Epoch 103: | Loss: 0.00648 | Acc: 99.747\n",
      "Epoch 104: | Loss: 0.00530 | Acc: 99.797\n",
      "Epoch 105: | Loss: 0.00537 | Acc: 99.773\n",
      "Epoch 106: | Loss: 0.00435 | Acc: 99.836\n",
      "Epoch 107: | Loss: 0.00562 | Acc: 99.766\n",
      "Epoch 108: | Loss: 0.00491 | Acc: 99.801\n",
      "Epoch 109: | Loss: 0.00524 | Acc: 99.784\n",
      "Epoch 110: | Loss: 0.00625 | Acc: 99.749\n",
      "Epoch 111: | Loss: 0.00527 | Acc: 99.790\n",
      "Epoch 112: | Loss: 0.00489 | Acc: 99.810\n",
      "Epoch 113: | Loss: 0.00472 | Acc: 99.793\n",
      "Epoch 114: | Loss: 0.00518 | Acc: 99.806\n",
      "Epoch 115: | Loss: 0.00418 | Acc: 99.841\n",
      "Epoch 116: | Loss: 0.00507 | Acc: 99.799\n",
      "Epoch 117: | Loss: 0.00525 | Acc: 99.819\n",
      "Epoch 118: | Loss: 0.00425 | Acc: 99.833\n",
      "Epoch 119: | Loss: 0.00444 | Acc: 99.820\n",
      "Epoch 120: | Loss: 0.00426 | Acc: 99.827\n",
      "Epoch 121: | Loss: 0.00523 | Acc: 99.800\n",
      "Epoch 122: | Loss: 0.00508 | Acc: 99.810\n",
      "Epoch 123: | Loss: 0.00390 | Acc: 99.853\n",
      "Epoch 124: | Loss: 0.00478 | Acc: 99.830\n",
      "Epoch 125: | Loss: 0.00461 | Acc: 99.819\n",
      "Epoch 126: | Loss: 0.00321 | Acc: 99.870\n",
      "Epoch 127: | Loss: 0.00437 | Acc: 99.809\n",
      "Epoch 128: | Loss: 0.00505 | Acc: 99.789\n",
      "Epoch 129: | Loss: 0.00419 | Acc: 99.827\n",
      "Epoch 130: | Loss: 0.00449 | Acc: 99.814\n",
      "Epoch 131: | Loss: 0.00390 | Acc: 99.843\n",
      "Epoch 132: | Loss: 0.00400 | Acc: 99.837\n",
      "Epoch 133: | Loss: 0.00372 | Acc: 99.843\n",
      "Epoch 134: | Loss: 0.00478 | Acc: 99.806\n",
      "Epoch 135: | Loss: 0.00361 | Acc: 99.850\n",
      "Epoch 136: | Loss: 0.00420 | Acc: 99.836\n",
      "Epoch 137: | Loss: 0.00466 | Acc: 99.821\n",
      "Epoch 138: | Loss: 0.00384 | Acc: 99.837\n",
      "Epoch 139: | Loss: 0.00335 | Acc: 99.879\n",
      "Epoch 140: | Loss: 0.00366 | Acc: 99.851\n",
      "Epoch 141: | Loss: 0.00453 | Acc: 99.813\n",
      "Epoch 142: | Loss: 0.00438 | Acc: 99.826\n",
      "Epoch 143: | Loss: 0.00408 | Acc: 99.831\n",
      "Epoch 144: | Loss: 0.00354 | Acc: 99.860\n",
      "Epoch 145: | Loss: 0.00333 | Acc: 99.863\n",
      "Epoch 146: | Loss: 0.00417 | Acc: 99.833\n",
      "Epoch 147: | Loss: 0.00332 | Acc: 99.857\n",
      "Epoch 148: | Loss: 0.00408 | Acc: 99.843\n",
      "Epoch 149: | Loss: 0.00491 | Acc: 99.813\n",
      "Epoch 150: | Loss: 0.00320 | Acc: 99.871\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "972cc207",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_test_tag = torch.round(torch.sigmoid(y_test_pred))\n",
    "        y_test_list.append(y_test_tag.cpu().int().numpy())\n",
    "y_test_list = [a.squeeze().tolist() for a in y_test_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "62dafb14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.871521610420367"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,np.array(y_test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a3ddb088",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_list = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_batch in predict_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_predict_pred = model(X_batch)\n",
    "        y_predict_tag = torch.round(torch.sigmoid(y_predict_pred))\n",
    "        y_predict_list.append(y_predict_tag.cpu().int().numpy())\n",
    "y_predict_list = [a.squeeze().tolist() for a in y_predict_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a4cded1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.array(y_predict_list)).to_csv('sample_nn.csv', index=False, header=False, float_format='%.0f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cabf91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
